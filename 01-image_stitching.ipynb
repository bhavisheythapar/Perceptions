{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Authors      : Aditya Jain & Bhavishey Thapar\n",
    "Date started : November 22, 2022\n",
    "About        : AER1515 Project project; image stitching for drone imagery\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(img1, img2, H):\n",
    "    \"\"\"\n",
    "    function for warping/stitching two images using the homography matrix H\n",
    "    \n",
    "    Args:\n",
    "        img1  : first image, or source image\n",
    "        img2  : second image, that needs to be mapped to the frame of img1\n",
    "        H     : homography matrix that maps img2 to img1        \n",
    "        \n",
    "    Returns:\n",
    "        output_img: img2 warped to img1 using H\n",
    "    \"\"\"\n",
    "    \n",
    "    rows1, cols1 = img1.shape[:2]\n",
    "    rows2, cols2 = img2.shape[:2]\n",
    "\n",
    "    points_1      = np.float32([[0,0], [0,rows1], [cols1,rows1], [cols1,0]]).reshape(-1,1,2)\n",
    "    temp_points   = np.float32([[0,0], [0,rows2], [cols2,rows2], [cols2,0]]).reshape(-1,1,2)\n",
    "    points_2      = cv2.perspectiveTransform(temp_points, H)\n",
    "    points_concat = np.concatenate((points_1, points_2), axis=0)    \n",
    "\n",
    "    [x_min, y_min]   = np.int32(points_concat.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max]   = np.int32(points_concat.max(axis=0).ravel() + 0.5)\n",
    "    translation_dist = [-x_min,-y_min]\n",
    "    H_translation    = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0,0,1]])\n",
    "\n",
    "    output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
    "    frame_size = output_img.shape\n",
    "    new_image  = img2.shape\n",
    "    output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
    "    \n",
    "    origin_r = int(points_2[0][0][1])\n",
    "    origin_c = int(points_2[0][0][0])\n",
    "    \n",
    "    # if the origin of projected image is out of bounds, then mapping to ()\n",
    "    if origin_r < 0:\n",
    "        origin_r = 0\n",
    "    if origin_c < 0:\n",
    "        origin_c = 0\n",
    "        \n",
    "    # Clipping the new image, if it's size is more than the frame    \n",
    "    if new_image[0] > frame_size[0]-origin_r:\n",
    "        img2 = img2[0:frame_size[0]-origin_r,:]\n",
    "        \n",
    "    if new_image[1] > frame_size[1]-origin_c:\n",
    "        img2 = img2[:,0:frame_size[1]-origin_c]    \n",
    "            \n",
    "    output_img[origin_r:new_image[0]+origin_r, origin_c:new_image[1]+origin_c] = img2    \n",
    "    \n",
    "    return output_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mosaic(raw_image_list, num_imgs_to_use, mosaic_name, \n",
    "                 num_featues=1000, reproj_thresh=5.0):\n",
    "    \"\"\"\n",
    "    main function for image stitching \n",
    "    \n",
    "    Args:\n",
    "        raw_image_list  : sorted list of raw image paths to be stitched\n",
    "        num_imgs_to_use : number of images to build a mosaic for\n",
    "        mosaic_name     : name of the final sitched image\n",
    "        num_featues     : number of keypoints to extract from feature detector; optional; default=1000\n",
    "        reproj_thresh   : reprojection error threshold in pixels; optional; default=5.0\n",
    "        \n",
    "        \n",
    "    Returns:\n",
    "        avg_repro_error : list of average reprojection error\n",
    "        matches         : list of number of good matches\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_repro_error = []  # list of average reprojection error\n",
    "    matches_list    = []  # list of number of good matches at every stage\n",
    "    sift            = cv2.SIFT_create(num_featues)\n",
    "    \n",
    "    # starting out with first image\n",
    "    first_image   = cv2.imread(raw_image_list[0])\n",
    "    height, width = first_image.shape[:2]\n",
    "    first_image   = cv2.resize(first_image, (int(width/4), int(height/4)))\n",
    "    final_mosaic  = first_image\n",
    "    img_count     = 0\n",
    "    \n",
    "    for img_name in raw_image_list[1:]:\n",
    "        image = cv2.imread(img_name)              \n",
    "        height, width = image.shape[:2]        \n",
    "        image = cv2.resize(image, (int(width/4), int(height/4)))\n",
    "\n",
    "        # Find the features\n",
    "        kp1, des1 = sift.detectAndCompute(cv2.cvtColor(final_mosaic,cv2.COLOR_BGR2GRAY),None)  \n",
    "        kp2, des2 = sift.detectAndCompute(cv2.cvtColor(image,cv2.COLOR_BGR2GRAY),None)\n",
    "        \n",
    "        # Feature matching      \n",
    "        FLANN_INDEX_KDTREE = 0\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks = 50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1,des2,k=2)        \n",
    "        \n",
    "        # Store all good matches as per Lowe's ratio test\n",
    "        good       = []\n",
    "        all_points = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good.append(m)                \n",
    "            all_points.append(m)        \n",
    "        matches_list.append(len(good))        \n",
    "        \n",
    "        # Find homography\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)        \n",
    "        all_src_pts = np.float32([ kp1[m.queryIdx].pt for m in all_points]).reshape(-1,1,2)\n",
    "        all_dst_pts = np.float32([ kp2[m.trainIdx].pt for m in all_points]).reshape(-1,1,2)        \n",
    "        M, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC,reproj_thresh)\n",
    "        \n",
    "        # Find the euclidean distance error\n",
    "        src_pts      = np.array(src_pts)    \n",
    "        dst_pts      = np.array(dst_pts)\n",
    "        dst_pts      = np.reshape(dst_pts, (len(dst_pts), 2))\n",
    "        ones         = np.ones(len(src_pts))    \n",
    "        test_pts     = np.transpose(np.reshape(src_pts, (len(src_pts), 2)))\n",
    "        test_pts_hom = np.vstack((test_pts, ones))  \n",
    "        ## projecting the points in test image to collage image using homography matrix\n",
    "        projected_pts_H  = np.matmul(M, test_pts_hom)      \n",
    "        projected_pts_nH = np.transpose(np.array([np.true_divide(projected_pts_H[0,:], projected_pts_H[2,:]), \\\n",
    "                                                  np.true_divide(projected_pts_H[1,:], projected_pts_H[2,:])]))        \n",
    "        error     = int(np.sum(np.linalg.norm(projected_pts_nH-dst_pts, axis=1)))\n",
    "        avg_error = np.divide(np.array(error), np.array(len(src_pts)))     \n",
    "        avg_repro_error.append(avg_error)\n",
    "        \n",
    "        # Apply homography to current image and obtain the resultant mosaic\n",
    "        final_mosaic = stitch_images(final_mosaic, image, M)\n",
    "        cv2.imwrite(mosaic_name, final_mosaic)        \n",
    "        \n",
    "        img_count += 1        \n",
    "        if img_count==num_imgs_to_use:\n",
    "            break\n",
    "    \n",
    "    return avg_repro_error, matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allPoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m mosaic_name     \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchandigarh_20images.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_mosaic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_image_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_imgs_to_use\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmosaic_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mbuild_mosaic\u001b[0;34m(raw_image_list, num_imgs_to_use, mosaic_name, num_featues, reproj_thresh)\u001b[0m\n\u001b[1;32m     56\u001b[0m src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([ kp1[m\u001b[38;5;241m.\u001b[39mqueryIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m good ])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     57\u001b[0m dst_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([ kp2[m\u001b[38;5;241m.\u001b[39mtrainIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m good ])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)        \n\u001b[0;32m---> 58\u001b[0m all_src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([ kp1[m\u001b[38;5;241m.\u001b[39mqueryIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mallPoints\u001b[49m ])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     59\u001b[0m all_dst_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([ kp2[m\u001b[38;5;241m.\u001b[39mtrainIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m allPoints ])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)        \n\u001b[1;32m     60\u001b[0m M, mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindHomography(dst_pts, src_pts, cv2\u001b[38;5;241m.\u001b[39mRANSAC,reproj_thresh)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'allPoints' is not defined"
     ]
    }
   ],
   "source": [
    "raw_image_list  = sorted(glob.glob('./raw_images/*.JPG'))\n",
    "num_imgs_to_use = 10\n",
    "mosaic_name     = 'chandigarh_20images.png'\n",
    "\n",
    "if __name__=='__main__':\n",
    "    _, _ = build_mosaic(raw_image_list, num_imgs_to_use, mosaic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (milamoth_ai)",
   "language": "python",
   "name": "milamoth_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
